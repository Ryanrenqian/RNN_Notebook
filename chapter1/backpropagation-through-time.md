# Backpropagation through time

为了计算反向传播的过程需要定义对单个位置上的预测值的损失函数采用交叉熵损失函数，如下所示：

$$L^{<t>}(\bar y^{<t>},y^{<t>})=-y^{<t>}log \bar y^{<t>} -(1-y^{<t>})log(1-\bar y^{<t>})$$

将单个位置的损失函数相加得到整个序列的损失函数如下：

$$J= \sum L^{<t>}(\bar y^{<t>},y^{<t>})$$

反向传播以图3-1为例。

![](/Chapter1/2-1.png)

在这个计算图中，通过可以计算对应的损失函数，于是计算出第一个时间步的损失函数，然后计算出第二个时间步的损失函数，然后是第三个时间步，一直到最后一个时间步，最后为了计算出总体损失函数，我们要把它们都加起来，通过下面的等式计算出最后的，也就是把每个单独时间步的损失函数都加起来。

这就是完整的计算图，在之前的例子中，你已经见过反向传播，所以你应该能够想得到反向传播算法需要在相反的方向上进行计算和传递信息，最终你做的就是把前向传播的箭头都反过来，在这之后你就可以计算出所有合适的量，然后你就可以通过导数相关的参数，用梯度下降法来更新参数。

在这个反向传播的过程中，最重要的信息传递或者说最重要的递归运算就是这个从右到左的运算，这也就是为什么这个算法有一个很别致的名字，叫做**“通过（穿越）时间反向传播**（**backpropagation through time**）”。取这个名字的原因是对于前向传播，你需要从左到右进行计算，在这个过程中，时刻不断增加。而对于反向传播，你需要从右到左进行计算，就像时间倒流。“通过时间反向传播”，就像穿越时光，这种说法听起来就像是你需要一台时光机来实现这个算法一样。

更详细的计算公式如下：

![](/chapter1/2-0.png)因此我们需要利用Cache保存Forward中的结果

